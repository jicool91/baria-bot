import os
import logging
from fastapi import FastAPI
from pydantic import BaseModel
from .raglib import search, ensure_schema, add_sample_data, get_chunks_count
from openai import OpenAI

OLLAMA_BASE_URL = os.getenv("OLLAMA_BASE_URL", "http://ollama:11434/v1")
OLLAMA_MODEL = os.getenv("OLLAMA_MODEL", "llama3.1:8b")

# –°–æ–∑–¥–∞–µ–º –∫–ª–∏–µ–Ω—Ç OpenAI –¥–ª—è —Ä–∞–±–æ—Ç—ã —Å Ollama
client = OpenAI(base_url=OLLAMA_BASE_URL, api_key="ollama")

app = FastAPI(title="Baria Bot RAG Service", version="1.0.0")

class AskReq(BaseModel):
    user_id: int
    question: str

class AskResp(BaseModel):
    answer: str
    sources: list[str] = []

SYSTEM_PROMPT = (
    "–¢—ã ‚Äî –∞—Å—Å–∏—Å—Ç–µ–Ω—Ç –ø–æ —Å–æ–ø—Ä–æ–≤–æ–∂–¥–µ–Ω–∏—é –ø–æ—Å–ª–µ –±–∞—Ä–∏–∞—Ç—Ä–∏—á–µ—Å–∫–æ–π –æ–ø–µ—Ä–∞—Ü–∏–∏. "
    "–û—Ç–≤–µ—á–∞–π —Å—Ç—Ä–æ–≥–æ –Ω–∞ –æ—Å–Ω–æ–≤–µ –ø—Ä–µ–¥–æ—Å—Ç–∞–≤–ª–µ–Ω–Ω—ã—Ö –º–µ—Ç–æ–¥–∏—á–µ–∫. "
    "–ù–ï —Å—Ç–∞–≤—å –¥–∏–∞–≥–Ω–æ–∑—ã, –ù–ï –¥–∞–≤–∞–π –º–µ–¥–∏–∫–∞–º–µ–Ω—Ç–æ–∑–Ω—ã—Ö –Ω–∞–∑–Ω–∞—á–µ–Ω–∏–π. "
    "–í—Å–µ–≥–¥–∞ –¥–æ–±–∞–≤–ª—è–π –¥–∏—Å–∫–ª–µ–π–º–µ—Ä –æ –Ω–µ–æ–±—Ö–æ–¥–∏–º–æ—Å—Ç–∏ –∫–æ–Ω—Å—É–ª—å—Ç–∞—Ü–∏–∏ —Å –≤—Ä–∞—á–æ–º –ø—Ä–∏ —É—Ö—É–¥—à–µ–Ω–∏–∏ —Å–æ—Å—Ç–æ—è–Ω–∏—è."
)

@app.on_event("startup")
async def startup_event():
    """–ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è –ø—Ä–∏ –∑–∞–ø—É—Å–∫–µ —Å–µ—Ä–≤–∏—Å–∞"""
    try:
        logging.info("üöÄ –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è RAG —Å–µ—Ä–≤–∏—Å–∞...")
        ensure_schema()

        # –ü—Ä–æ–≤–µ—Ä—è–µ–º –µ—Å—Ç—å –ª–∏ –¥–∞–Ω–Ω—ã–µ, –µ—Å–ª–∏ –Ω–µ—Ç - –¥–æ–±–∞–≤–ª—è–µ–º —Ç–µ—Å—Ç–æ–≤—ã–µ
        chunks_count = get_chunks_count()
        if chunks_count == 0:
            logging.info("üìö –î–æ–±–∞–≤–ª—è–µ–º —Ç–µ—Å—Ç–æ–≤—ã–µ –¥–∞–Ω–Ω—ã–µ...")
            added = add_sample_data()
            logging.info(f"‚úÖ –î–æ–±–∞–≤–ª–µ–Ω–æ {added} —Ç–µ—Å—Ç–æ–≤—ã—Ö –∑–∞–ø–∏—Å–µ–π")
        else:
            logging.info(f"‚úÖ –í –±–∞–∑–µ —É–∂–µ –µ—Å—Ç—å {chunks_count} –∑–∞–ø–∏—Å–µ–π")

        logging.info("üéâ RAG —Å–µ—Ä–≤–∏—Å –≥–æ—Ç–æ–≤ –∫ —Ä–∞–±–æ—Ç–µ")
    except Exception as e:
        logging.error(f"‚ùå –û—à–∏–±–∫–∞ –∏–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏–∏: {e}")
        import traceback
        traceback.print_exc()

@app.get("/")
async def root():
    return {"status": "RAG service is running", "version": "1.0.0"}

@app.get("/health")
async def health_check():
    try:
        logging.info("üîç –ü—Ä–æ–≤–µ—Ä–∫–∞ –∑–¥–æ—Ä–æ–≤—å—è —Å–µ—Ä–≤–∏—Å–∞...")

        # –ü—Ä–æ–≤–µ—Ä—è–µ–º –ø–æ–¥–∫–ª—é—á–µ–Ω–∏–µ –∫ –ë–î
        chunks_count = get_chunks_count()
        logging.info(f"üìä –ù–∞–π–¥–µ–Ω–æ {chunks_count} —á–∞–Ω–∫–æ–≤ –≤ –±–∞–∑–µ")

        if chunks_count == 0:
            logging.info("üìö –ü—ã—Ç–∞–µ–º—Å—è –¥–æ–±–∞–≤–∏—Ç—å —Ç–µ—Å—Ç–æ–≤—ã–µ –¥–∞–Ω–Ω—ã–µ...")
            added = add_sample_data()
            chunks_count = get_chunks_count()
            logging.info(f"‚úÖ –î–æ–±–∞–≤–ª–µ–Ω–æ {added} –∑–∞–ø–∏—Å–µ–π, –≤—Å–µ–≥–æ: {chunks_count}")

        return {"status": "healthy", "db_connection": "ok", "chunks_count": chunks_count}
    except Exception as e:
        logging.error(f"‚ùå –û—à–∏–±–∫–∞ health check: {e}")
        import traceback
        traceback.print_exc()
        return {"status": "unhealthy", "error": str(e)}

@app.post("/ask", response_model=AskResp)
async def ask(req: AskReq):
    try:
        # –ò—â–µ–º —Ä–µ–ª–µ–≤–∞–Ω—Ç–Ω—ã–µ —Ñ—Ä–∞–≥–º–µ–Ω—Ç—ã
        contexts = search(req.question, top_k=5)

        if not contexts:
            return AskResp(
                answer="–ò–∑–≤–∏–Ω–∏—Ç–µ, –Ω–µ –Ω–∞–π–¥–µ–Ω–æ —Ä–µ–ª–µ–≤–∞–Ω—Ç–Ω–æ–π –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏–∏ –≤ –±–∞–∑–µ –∑–Ω–∞–Ω–∏–π. –û–±—Ä–∞—Ç–∏—Ç–µ—Å—å –∫ –≤–∞—à–µ–º—É –≤—Ä–∞—á—É –∑–∞ –∫–æ–Ω—Å—É–ª—å—Ç–∞—Ü–∏–µ–π.",
                sources=[]
            )

        context_text = "\n\n".join([f"–ò—Å—Ç–æ—á–Ω–∏–∫: {c['source']}\n{c['content']}" for c in contexts])
        sources = list(set([c['source'] for c in contexts]))

        user_prompt = (
            f"–ö–æ–Ω—Ç–µ–∫—Å—Ç –∏–∑ –º–µ–¥–∏—Ü–∏–Ω—Å–∫–∏—Ö –ø—Ä–æ—Ç–æ–∫–æ–ª–æ–≤:\n{context_text}\n\n"
            f"–í–æ–ø—Ä–æ—Å –ø–∞—Ü–∏–µ–Ω—Ç–∞: {req.question}\n\n"
            f"–î–∞–π –∫—Ä–∞—Ç–∫–∏–π –æ—Ç–≤–µ—Ç –Ω–∞ –æ—Å–Ω–æ–≤–µ —Ç–æ–ª—å–∫–æ –ø—Ä–µ–¥–æ—Å—Ç–∞–≤–ª–µ–Ω–Ω–æ–≥–æ –∫–æ–Ω—Ç–µ–∫—Å—Ç–∞. "
            f"–ï—Å–ª–∏ –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏–∏ –Ω–µ–¥–æ—Å—Ç–∞—Ç–æ—á–Ω–æ, –Ω–∞–ø—Ä–∞–≤—å –∫ –≤—Ä–∞—á—É."
        )

        # –ó–∞–ø—Ä–æ—Å –∫ LLM
        resp = client.chat.completions.create(
            model=OLLAMA_MODEL,
            messages=[
                {"role": "system", "content": SYSTEM_PROMPT},
                {"role": "user", "content": user_prompt},
            ],
            temperature=0.2,
            max_tokens=500
        )

        answer = resp.choices[0].message.content.strip()

        # –î–æ–±–∞–≤–ª—è–µ–º –æ–±—è–∑–∞—Ç–µ–ª—å–Ω—ã–π –¥–∏—Å–∫–ª–µ–π–º–µ—Ä
        disclaimer = "\n\n‚ö†Ô∏è –≠—Ç–æ –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏–æ–Ω–Ω–∞—è —Å–ø—Ä–∞–≤–∫–∞ –Ω–∞ –æ—Å–Ω–æ–≤–µ –º–µ–¥–∏—Ü–∏–Ω—Å–∫–∏—Ö –ø—Ä–æ—Ç–æ–∫–æ–ª–æ–≤. –ü—Ä–∏ —É—Ö—É–¥—à–µ–Ω–∏–∏ —Å–∞–º–æ—á—É–≤—Å—Ç–≤–∏—è –æ–±—Ä–∞—Ç–∏—Ç–µ—Å—å –∫ –≤—Ä–∞—á—É."
        final_answer = answer + disclaimer

        return AskResp(answer=final_answer, sources=sources)

    except Exception as e:
        logging.error(f"–û—à–∏–±–∫–∞ –≤ /ask: {e}")
        return AskResp(
            answer="–ò–∑–≤–∏–Ω–∏—Ç–µ, –ø—Ä–æ–∏–∑–æ—à–ª–∞ –æ—à–∏–±–∫–∞ –ø—Ä–∏ –æ–±—Ä–∞–±–æ—Ç–∫–µ –∑–∞–ø—Ä–æ—Å–∞. –ü–æ–ø—Ä–æ–±—É–π—Ç–µ –ø–æ–∑–∂–µ –∏–ª–∏ –æ–±—Ä–∞—Ç–∏—Ç–µ—Å—å –∫ –≤—Ä–∞—á—É.",
            sources=[]
        )